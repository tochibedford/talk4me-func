const { Configuration, OpenAIApi } = require("openai");
require("dotenv").config();

const configuration = new Configuration({
  apiKey: process.env.OPENAI_KEY,
});
const openai = new OpenAIApi(configuration);

function* generateBatchedTweets(tweets, maxTokens = 3100, tokenLength = 4.5) {
  const tweetBatch = [];
  let totalTokens = 0;

  for (const tweet of tweets) {
    if (totalTokens >= maxTokens) {
      const result = [...tweetBatch];
      tweetBatch.length = 0;
      totalTokens = 0;
      yield result;
    }
    totalTokens += tweet.length / tokenLength;
    tweetBatch.push(tweet);
  }

  yield tweetBatch;
}

exports.genNewTweets = async (req, res) => {
  if (req.method !== "POST") {
    res.status(405).send({ message: "Only POST requests allowed" });
    return;
  }
  const { tweets, twitterId } = req.body;
  const endPrompt = `You are now to act as if you are the one that made the tweets, in other words, you are now @${twitterId}, so you must reply as if you are them, based on the above tweets. So, generate 5 tweets @${twitterId} could potentially tweet strictly based on the above tweets. Don't include @ handles and quotes by yourself, as this will be mostly generated by the people to whom you are replying. Remember, strictly based on the above tweets.\n1.`;
  const tweetBatches = generateBatchedTweets(tweets, 300);
  let tweetBatch = tweetBatches.next();
  const openaiResponses = [];
  let count = 0;
  while (!tweetBatch.done) {
    if (count == 2) {
      break;
    }

    if (Math.random() > 0.5) {
      const prompt = `These are a bunch of tweets from the twitter user @${twitterId}: [\n ${tweetBatch.value} \n]\n${endPrompt}`;
      const response = await openai.createCompletion({
        model: "text-davinci-003",
        prompt: prompt,
        max_tokens: 300,
        temperature: 0.69,
      });
      openaiResponses.push(response.data);
      count++;
    }
    tweetBatch = tweetBatches.next();
  }
  res.status(200).send({ message: openaiResponses });
};
